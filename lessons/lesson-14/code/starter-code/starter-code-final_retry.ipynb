{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name interfaces",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-b0bca535085e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# do a pip install gensim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# do python -m spacy.en.download if you have not already\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword2vec\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mcxx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Zane_Harris\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\gensim-0.12.4-py2.7-win-amd64.egg\\gensim\\__init__.pyc\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \"\"\"\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mparsing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatutils\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterfaces\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpora\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msimilarities\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msummarization\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Zane_Harris\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\gensim-0.12.4-py2.7-win-amd64.egg\\gensim\\models\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# bring model classes directly into package namespace, to save some typing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mhdpmodel\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mHdpModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mldamodel\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLdaModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mlsimodel\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLsiModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Zane_Harris\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\gensim-0.12.4-py2.7-win-amd64.egg\\gensim\\models\\hdpmodel.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspecial\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minterfaces\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmoves\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name interfaces"
     ]
    }
   ],
   "source": [
    "# spacy is used for pre-processing and traditional NLP\n",
    "import scipy\n",
    "import numpy\n",
    "import spacy\n",
    "from spacy.en import English\n",
    "\n",
    "# Gensim is used for LDA and word2vec\n",
    "# do a pip install gensim\n",
    "# do python -m spacy.en.download if you have not already\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "cxx = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Write a function that can take a take a sentence parsed by `spacy` and \n",
    "# identify if it mentions a company named 'Google'. \n",
    "# Remember, `spacy` can find entities and code them `ORG` if they are a company.\n",
    "# call the function mentions_company, and it will take in two parameters, parsed which is a string,\n",
    "# and the company, which will be a string of the company you will search for, in our case google\n",
    "# The function will return a Boolean (True or False) if entity.text == company and entity.label_ == 'ORG':\n",
    "\n",
    "def mentions_company(parsed, company):\n",
    "    for entity in parsed.ents:\n",
    "        if (entity.text == company and entity.label_ == \"org\"):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write a function that can take a sentence parsed by `spacy` \n",
    "# and return the verbs of the sentence (preferably lemmatized)\n",
    "# call the function get_actions, it will take one parameter which is of type string, which will\n",
    "# be your parsed string\n",
    "# The function will return a list of actions, if the word in the parsed sentence is a verb\n",
    "\"\"\"\"\"\n",
    "def get_actions(parsed):\n",
    "    actions = []\n",
    "    for x in parsed:\n",
    "        if x.pos == spacy.parts_of_speech.VERB:\n",
    "            actions.append( x.lemma_ )\n",
    "    \n",
    "    return actions\n",
    "\"\"\"\"\"\n",
    "\n",
    "def get_actions(parsed):\n",
    "    actions = [el.lemma_\n",
    "                for el in parsed\n",
    "                if el.pos == spacy.parts_of_speech.VERB\n",
    "               ]\n",
    "    return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write a function that identifies countries - HINT: the entity label for \n",
    "# countries is GPE (or GeoPolitical Entity)\n",
    "# The function will be called mentions country, and will take two parameters, the parsed string\n",
    "# and the country name (string) type you will search for within entity.text (Hint)\n",
    "# The function will return a boolean type (True or False)\n",
    "\n",
    "def mentions_country(parsed, country):\n",
    "    objects = parsed.ents\n",
    "    for entity in objects:\n",
    "        if entity.text == country and entity.label_ == \"GPE\":\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @cerenomri: \"Literally every US ally in Mideast is on brink of hot war w/ Iran, so we're going to release $100 billion to Iran this mont\n",
      "\n",
      "GOBE! Iran warns Nigeria to release Shiite leader El-Zakzaky - SEE https://t.co/TRshnC6sVU\n",
      "\n",
      "GOBE! Iran warns Nigeria to release Shiite leader El-Zakzaky - SEE https://t.co/SlvcQtk3vE\n",
      "\n",
      "RT @Vatescorp: #Sudan: Ministry of Foreign Affairs announced Khartoum has decided to sever diplomatic ties with #Iran https://t.co/ofQG8gtL\n",
      "\n",
      "RT @cerenomri: \"Literally every US ally in Mideast is on brink of hot war w/ Iran, so we're going to release $100 billion to Iran this mont\n",
      "\n",
      "Hhmmm. Iran claiming to have 'warned Nigeria' to release detained Shiite leader.... @afalli\n",
      "\n",
      "RT @KenGardner11: Arab allies are breaking diplomatic relations with Iran. Obama's response? Release $100 billion to Iran. The quintessenti\n",
      "\n",
      "RT @cerenomri: \"Literally every US ally in Mideast is on brink of hot war w/ Iran, so we're going to release $100 billion to Iran this mont\n",
      "\n",
      "RT @NEWS957: Saudi Arabia announces it is severing ties with Iran, Canada urging diplomacy https://t.co/7JE6dOHoQV\n",
      "\n",
      "RT @ahmed: Full transcript of press conference where Saudi FM @AdelAljubeir announced cutting diplomatic relations with Iran https://t.co/L\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Word2Vec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-a75e22594ccb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;31m# Solution to 2b\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;31m# Build a `word2vec` model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_split\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;31m# Solution to 2c\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Word2Vec' is not defined"
     ]
    }
   ],
   "source": [
    "# Note, this block of code will ONLY work for you, IFF, you called the functions \n",
    "# the correct names in the cells above\n",
    "if __name__ == '__main__':\n",
    "    # Loading the tweet data\n",
    "    tweets = [unicode(tweet, errors='ignore') for tweet in open('../../assets/dataset/captured-tweets.txt', 'r')]\n",
    "\n",
    "    # Setting up spacy\n",
    "    nlp_toolkit = English()\n",
    "\n",
    "    # Solution to 1d\n",
    "    # For each tweet, parse it using `spacy` and print out if the tweet \n",
    "    # has 'release' or 'announce' as a verb.\n",
    "    for tweet in tweets:\n",
    "        parsed = nlp_toolkit(tweet)\n",
    "\n",
    "        if mentions_company(parsed, 'Google'):\n",
    "            actions = get_actions(parsed)\n",
    "            if 'release' in actions or 'announce' in actions:\n",
    "                print(tweet)\n",
    "\n",
    "    # Solution to 1f\n",
    "    # Re-run (d) find country tweets that discuss 'Iran' announcing or releasing.\n",
    "    for tweet in tweets:\n",
    "        parsed = nlp_toolkit(tweet)\n",
    "\n",
    "        if mentions_country(parsed, 'Iran'):\n",
    "            actions = get_actions(parsed)\n",
    "            if 'release' in actions or 'announce' in actions:\n",
    "                print(tweet)\n",
    "\n",
    "    # Solution to 2a\n",
    "    # First take the collection of tweets and tokenize them using `spacy`\n",
    "\n",
    "    # Many solutions here!\n",
    "    # I decided to lemmatized the verbs for easier searching and keep symbols\n",
    "    # and punctuations\n",
    "\n",
    "    text_split = [[x.text if x.pos != spacy.parts_of_speech.VERB else x.lemma_ \n",
    "                    for x in nlp_toolkit(t)] for t in tweets]\n",
    "\n",
    "    # Solution to 2b\n",
    "    # Build a `word2vec` model\n",
    "    model = Word2Vec(text_split, size=100, window=4, min_count=5, workers=4)\n",
    "\n",
    "    # Solution to 2c\n",
    "    model.most_similar(positive=['Syria'])\n",
    "\n",
    "    # Solution to 3\n",
    "    # Filter tweets down to those that mention 'Iran' or similar entities and \n",
    "    # 'war' or similar entities\n",
    "\n",
    "    # a: Using spacy\n",
    "    for tweet in tweets:\n",
    "        parsed = nlp_toolkit(tweet)\n",
    "        if mentions_country(parsed, 'Iran') or mentions_country(parsed, 'Iraq'): # ... you could add more\n",
    "            if 'attack' in get_actions(parsed):\n",
    "                print(tweet)\n",
    "\n",
    "    # b: using similarity scores\n",
    "    for tweet in tweets:\n",
    "        parsed = nlp_toolkit(tweet)\n",
    "\n",
    "        similarity_to_iran = max([model.similarity('Iran', tok.text) for tok in parsed if tok.text in model.vocab], 0)\n",
    "        similarity_to_war = max([model.similarity('war', tok.text) for tok in parsed if tok.text in model.vocab], 0)\n",
    "        if similarity_to_iran > 0.75 and similarity_to_war > 0.75:\n",
    "            print(similarity_to_iran, similarity_to_war, tweet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
