{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# spacy is used for pre-processing and traditional NLP\n",
    "import spacy\n",
    "from spacy.en import English\n",
    "\n",
    "# Gensim is used for LDA and word2vec\n",
    "# do a pip install gensim\n",
    "# do python -m spacy.en.download if you have not already\n",
    "from gensim.models.word2vec import Word2Vec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write a function that can take a take a sentence parsed by `spacy` and \n",
    "# identify if it mentions a company named 'Google'. \n",
    "# Remember, `spacy` can find entities and code them `ORG` if they are a company.\n",
    "# call the function mentions_company, and it will take in two parameters, parsed which is a string,\n",
    "# and the company, which will be a string of the company you will search for, in our case google\n",
    "# The function will return a Boolean (True or False) if entity.text == company and entity.label_ == 'ORG':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write a function that can take a sentence parsed by `spacy` \n",
    "# and return the verbs of the sentence (preferably lemmatized)\n",
    "# call the function get_actions, it will take one parameter which is of type string, which will\n",
    "# be your parsed string\n",
    "# The function will return a list of actions, if the word in the parsed sentence is a verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write a function that identifies countries - HINT: the entity label for \n",
    "# countries is GPE (or GeoPolitical Entity)\n",
    "# The function will be called mentions country, and will take two parameters, the parsed string\n",
    "# and the country name (string) type you will search for within entity.text (Hint)\n",
    "# The function will return a boolean type (True or False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Note, this block of code will ONLY work for you, IFF, you called the functions \n",
    "# the correct names in the cells above\n",
    "if __name__ == '__main__':\n",
    "    # Loading the tweet data\n",
    "    tweets = [unicode(tweet, errors='ignore') for tweet in open('../../assets/dataset/captured-tweets.txt', 'r')]\n",
    "\n",
    "    # Setting up spacy\n",
    "    nlp_toolkit = English()\n",
    "\n",
    "    # Solution to 1d\n",
    "    # For each tweet, parse it using `spacy` and print out if the tweet \n",
    "    # has 'release' or 'announce' as a verb.\n",
    "    for tweet in tweets:\n",
    "        parsed = nlp_toolkit(tweet)\n",
    "\n",
    "        if mentions_company(parsed, 'Google'):\n",
    "            actions = get_actions(parsed)\n",
    "            if 'release' in actions or 'announce' in actions:\n",
    "                print(tweet)\n",
    "\n",
    "    # Solution to 1f\n",
    "    # Re-run (d) find country tweets that discuss 'Iran' announcing or releasing.\n",
    "    for tweet in tweets:\n",
    "        parsed = nlp_toolkit(tweet)\n",
    "\n",
    "        if mentions_country(parsed, 'Iran'):\n",
    "            actions = get_actions(parsed)\n",
    "            if 'release' in actions or 'announce' in actions:\n",
    "                print(tweet)\n",
    "\n",
    "    # Solution to 2a\n",
    "    # First take the collection of tweets and tokenize them using `spacy`\n",
    "\n",
    "    # Many solutions here!\n",
    "    # I decided to lemmatized the verbs for easier searching and keep symbols\n",
    "    # and punctuations\n",
    "\n",
    "    text_split = [[x.text if x.pos != spacy.parts_of_speech.VERB else x.lemma_ \n",
    "                    for x in nlp_toolkit(t)] for t in tweets]\n",
    "\n",
    "    # Solution to 2b\n",
    "    # Build a `word2vec` model\n",
    "    model = Word2Vec(text_split, size=100, window=4, min_count=5, workers=4)\n",
    "\n",
    "    # Solution to 2c\n",
    "    model.most_similar(positive=['Syria'])\n",
    "\n",
    "    # Solution to 3\n",
    "    # Filter tweets down to those that mention 'Iran' or similar entities and \n",
    "    # 'war' or similar entities\n",
    "\n",
    "    # a: Using spacy\n",
    "    for tweet in tweets:\n",
    "        parsed = nlp_toolkit(tweet)\n",
    "        if mentions_country(parsed, 'Iran') or mentions_country(parsed, 'Iraq'): # ... you could add more\n",
    "            if 'attack' in get_actions(parsed):\n",
    "                print(tweet)\n",
    "\n",
    "    # b: using similarity scores\n",
    "    for tweet in tweets:\n",
    "        parsed = nlp_toolkit(tweet)\n",
    "\n",
    "        similarity_to_iran = max([model.similarity('Iran', tok.text) for tok in parsed if tok.text in model.vocab], 0)\n",
    "        similarity_to_war = max([model.similarity('war', tok.text) for tok in parsed if tok.text in model.vocab], 0)\n",
    "        if similarity_to_iran > 0.75 and similarity_to_war > 0.75:\n",
    "            print(similarity_to_iran, similarity_to_war, tweet)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
