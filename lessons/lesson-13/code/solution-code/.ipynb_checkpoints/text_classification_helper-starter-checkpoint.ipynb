{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied (use --upgrade to upgrade): numpy in c:\\users\\zane_harris\\appdata\\local\\continuum\\anaconda2\\lib\\site-packages\n"
     ]
    }
   ],
   "source": [
    "! pip install numpy\n",
    "# you can install packages with the exclamation point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import all dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# put your functions in one cell, call when you need\n",
    "def read_tsv(path):\n",
    "    return pd.read_csv(path, sep='\\t')\n",
    "def get_json_value(col,key):\n",
    "    return json.loads(col).get(key, '')\n",
    "def has_text(text,text_val):\n",
    "    try:\n",
    "        if 'recipe' in str(text).lower():\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    except: \n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"../../assets/dataset/stumbleupon.tsv\"\n",
    "data = read_tsv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "url                                object\n",
       "urlid                               int64\n",
       "boilerplate                        object\n",
       "alchemy_category                   object\n",
       "alchemy_category_score             object\n",
       "avglinksize                       float64\n",
       "commonlinkratio_1                 float64\n",
       "commonlinkratio_2                 float64\n",
       "commonlinkratio_3                 float64\n",
       "commonlinkratio_4                 float64\n",
       "compression_ratio                 float64\n",
       "embed_ratio                       float64\n",
       "framebased                          int64\n",
       "frameTagRatio                     float64\n",
       "hasDomainLink                       int64\n",
       "html_ratio                        float64\n",
       "image_ratio                       float64\n",
       "is_news                            object\n",
       "lengthyLinkDomain                   int64\n",
       "linkwordscore                       int64\n",
       "news_front_page                    object\n",
       "non_markup_alphanum_characters      int64\n",
       "numberOfLinks                       int64\n",
       "numwords_in_url                     int64\n",
       "parametrizedLinkRatio             float64\n",
       "spelling_errors_ratio             float64\n",
       "label                               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    0\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.label.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get the title text from the JsonObject \n",
    "# note the JsonObject is stored in column boilerplate\n",
    "# hint: look at function get_json_value above, it takes two inputs, \n",
    "# a dataframe column, and a key value to search the Json Dictionary,\n",
    "# call the new dataframe column \"title\" \n",
    "# hint: first input for get_json_value is a column, \n",
    "# and second input 'title'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the body text from the JsonObject\n",
    "# note the JsonObject is stored in column boilerplate\n",
    "# hint: look at function get_json_value above, it takes two inputs, \n",
    "# a dataframe column, and a key value to search the Json Dictionary,\n",
    "# call the new dataframe column \"body\" \n",
    "# hint: first input for get_json_value is a column, \n",
    "# and second input 'body'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now that you have two new columns in your dataframe, one which contains\n",
    "# only the title text of the website, and the other only body text\n",
    "# lets see if having the word 'recipe' in the title contributed to higher\n",
    "# evergreen websites?\n",
    "\n",
    "# hint, create new column called 'has_recipe', use function has_text,\n",
    "# which has two inputs, a column, \n",
    "# and the specific word you are looking for\n",
    "# no more hints!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# how many records had the word recipe in the title?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# how many records did not have the word recipe in the title?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Interpret Results Above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove all null values for title column, by replacing NaN with empty ''\n",
    "# maintain the 'title' column during the transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# lets make every word in the title a feature, \n",
    "# maybe other words besides recipes contributed to \n",
    "# higher evergreen websites?\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "                max_features = 1000, # max number of words to consider as features\n",
    "                ngram_range=(1, 2), \n",
    "                stop_words='english', # stop when you see word english\n",
    "                binary=True # each word will be a binary dummy categorical var\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use `fit` to learn the vocabulary of the titles\n",
    "vectorizer.fit(data.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use `tranform` to generate the sample X word matrix - one column per feature (word or n-grams)\n",
    "x_text_features = vectorizer.transform(data.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = data.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators = 20)\n",
    "# n_estimators = number of decision trees\n",
    "# other parameters such as max_depth, best_split, etc available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = cross_val_score(\n",
    "            model,  # your model\n",
    "            x_text_features,  # your features in vector form\n",
    "            labels,  # your labels (response/output/predictor)\n",
    "            scoring='roc_auc' # what metric do you want returned?\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('CV AUC {}, Average AUC {}'.format(scores, scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Identify the features you want from the original dataset\n",
    "other_features_columns = ['html_ratio', 'image_ratio']\n",
    "other_features = data[other_features_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Stack them horizontally together\n",
    "# This takes all of the word/n-gram columns and appends on two more columns for `html_ratio` and `image_ratio`\n",
    "features = hstack((x_text_features, other_features)).toarray()\n",
    "\n",
    "scores = cross_val_score(model, features, labels, scoring='roc_auc')\n",
    "print('CV AUC {}, Average AUC {}'.format(scores, scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# What features of these are most important, lets actually fit the model!\n",
    "model.fit(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_feature_names = vectorizer.get_feature_names() + other_features_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame(\n",
    "    {'Features' : all_feature_names, \n",
    "     'Importance Score': model.feature_importances_\n",
    "    }\n",
    ")\n",
    "\n",
    "# this makes a nice table for all features, \n",
    "# and there corresponding importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_importances.sort_values(\n",
    "   'Importance Score', \n",
    "    ascending=False\n",
    ").head(10) # sort_values defined for dataframe, default is ascending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your model was built from features coming from the vocabulary\n",
    "# of the title vs. the label. \n",
    "# Repeat the above process but with your features\n",
    "# coming from the 'body' column.\n",
    "# You must fit vocab in your body column, along with creating a vector with\n",
    "# all possible features in n columns (dummy variables)\n",
    "# hint: from vectorizor.transform(column_with_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
